#! /usr/bin/python3
#Generates a shell script with commands to 
#  1) Run the experiments based on the parameters passed.
#  2) Parse the logs files generated by wrk, the workload generator.
#  3) Send email to the user when the experiments start and update with the summary once the experiment is completed.

import sys,subprocess

# Some things have to be done before the start of the first iteration and some things after the final iteration. 
START_ITERATION = 0
FINAL_ITERATION = 1

def generate_commands(baseOutputDir,exptSetDir,baseVersionName,startIter,numIters,duration, rps, opScriptFname,appCode,monMachine,feMachine,emailRecipient, collect_jaeger=False):
    allCmds = []
    initCmd = "#! /bin/bash\n\n#Load Commands.."
    allCmds.append(initCmd)
    
    numThreads = 4
    numConns = 8
    numContsToTrack = 10000
    
    dockerStatsCmds = []
    allJaegerCmds = []
    
    inBetweenSleep = 50
    bufferTime = 0
    clusterNtpFreq = 3600//(duration+inBetweenSleep+bufferTime) # once in 8 iterations. roughly 
    #clusterNtpCmd = "cd ntp_stuff && ./synchronize_cluster_hosts.sh 1 /home/ubuntu/uservices/DeathStarBench/socialNetwork/cluster_setups/%s/hostToConfig.log && cd .. && sleep 30"%exptSetDir # If the first argument to synchronize_cluster_hosts is 1, it sets up the NTP cluster. If it is 0, it only collects the offset value from all the VMs in the cluster
    cumulNumIters = 0
    for curIter in range(startIter,startIter+numIters):
        if curIter == 0:
            duration = 300
        else:
            if appCode == "TT":
                duration =  1200
            else:
                duration = 900
            duration = 300
        for curRps in rps:
            curVersionName = str(baseVersionName)+"_rps"+str(curRps)
            fromBaseDirPath = str(exptSetDir)+"/"+str(curVersionName)
            mainDir = str(baseOutputDir)+"/"+str(fromBaseDirPath)
    
            print ("\t mainDir: %s "%(mainDir))
    
            try: 
                subprocess.check_output("mkdir -p "+str(mainDir),shell=True,universal_newlines=True)
                linkCmd = "cd "+str(baseOutputDir)+" && ln -s "+str(fromBaseDirPath)+" ."
                print ("\t linkCmd: %s "%(linkCmd))
                subprocess.check_output(linkCmd,shell=True,universal_newlines=True)
            except Exception as err:
                print ("\t Error: %s happened during creating and linking directory: %s "%(err,mainDir))
    
            outputDir = str(baseOutputDir)+"/"+str(curVersionName)+"/i"+str(curIter)
            exptName = str(curVersionName)+"_i"+str(curIter)
            print ("\t curIter: %d outputDir: %s "%(curIter,outputDir))
            try:
                subprocess.check_output("mkdir -p "+str(outputDir),shell=True,universal_newlines=True)
            except Exception as err:
                print ("\t Error: %s happened during creating and linking directory: %s "%(err,outputDir))
            #only add this to the 0th iteration of each experiment. In configuration project, we run 4 iterations for 1 RPS. The microservices are shut down and brought back for each RPS.

            
            if collect_jaeger and curIter == START_ITERATION:
                #allCmds.append("\n"+str(clusterNtpCmd)+"\n\n")
                pass
            #if(cumulNumIters%clusterNtpFreq==0):
            #    allCmds.append("\n"+str(clusterNtpCmd)+"\n\n")
            cumulNumIters+=1
    
    
            loadGenCmdPrefix = "./nodeMonitor.py "+str(baseOutputDir)+" "+str(curVersionName)+" "+str(curIter)
            loadGenCmd = str(loadGenCmdPrefix)+" "+str(numThreads)+" "+str(numConns)+" "+str(duration)+" "+str(curRps)+" "+str(numContsToTrack)+" "+str(appCode)+" "+str(emailRecipient)+" "+str(feMachine)
    
            collectDockerCmdPrefix = "./consolidateDockerStats.py "+str(baseOutputDir)+" "+str(curVersionName)+" "+str(curIter)
            collectDockerStatsCmd = str(collectDockerCmdPrefix)+" "+str(numThreads)+" "+str(numConns)+" "+str(duration)+" "+str(curRps)+" "+str(numContsToTrack)+" "+str(appCode)+" "+str(emailRecipient)+" "+str(feMachine)
            dockerStatsCmds.append(collectDockerStatsCmd)
    
            jaegerRunCmd = str(outputDir)+"/analyze.sh"
            if(cumulNumIters !=0 and curIter == FINAL_ITERATION): 
                allJaegerCmds.append(jaegerRunCmd) 
            print ("\t loadGenCmd: %s "%(loadGenCmd)) 
            cpCmd = "cp "+str(opScriptFname)+" *.py "+str(outputDir)
            allCmds.append("\n# Iter: "+str(curIter))
            allCmds.append(cpCmd)
            allCmds.append(loadGenCmd+"\n")
    
            summaryFilename =str(baseOutputDir)+"/"+str(curVersionName)+"/summary_avg_i"+str(curIter)+".log"
            grepAvgCmd = "grep Mean "+str(outputDir)+"/*.log > "+str(summaryFilename)
            allCmds.append(grepAvgCmd)
            allCmds.append(grepAvgCmd)
            
            grepNon2Cmd = "grep Non-2 "+str(outputDir)+"/*.log >> "+str(summaryFilename)
            allCmds.append(grepNon2Cmd)
            allCmds.append(grepNon2Cmd)
    
            content = "echo \" `cat "+str(summaryFilename)+"` \" "
            mailHeading = " \"Update expt version "+str(exptName)+" at `date` \" %s@cs.stonybrook.edu "%(emailRecipient) #-A "+str(summaryFilename)
            emailCmd = str(content)+"  | mail -s "+str(mailHeading)
    
            allCmds.append(emailCmd); 
    
            postProcTracesCmd = "./postProcTraces.py "+str(outputDir)+" "+str(curVersionName)+"_i"+str(curIter)+" "+str(appCode)+" "+str(monMachine)+" "+str(emailRecipient)
            allCmds.append(postProcTracesCmd+"\n")
    
            allCmds.append("sleep "+str(inBetweenSleep));
            # synchronization is needed only if you are collecting Jaeger traces.
            if collect_jaeger and curIter == FINAL_ITERATION :
                allCmds.append("cd ntp_stuff && ./synchronize_cluster_hosts.sh 0 /home/ubuntu/uservices/DeathStarBench/socialNetwork/cluster_setups/%s/hostToConfig.log && cd .."%exptSetDir)# Just collect the ntp client offset. Will help in debugging if the Jaeger traces seem off. 
    create_script(allCmds,curIter,opScriptFname,dockerStatsCmds,allJaegerCmds,collect_jaeger)

def create_script(allCmds,curIter,opScriptFname,dockerStatsCmds,allJaegerCmds,collect_jaeger):
    opScript = open(opScriptFname,'w')
    for curLine in allCmds:
        opScript.write(str(curLine)+"\n")
    add_dockerstats_collection(dockerStatsCmds,opScript)
    if collect_jaeger and curIter == FINAL_ITERATION:
            add_jaeger_scripts(allJaegerCmds,opScript)
    opScript.close()
    subprocess.check_output("chmod +x "+str(opScriptFname),shell=True,universal_newlines=True)

def add_dockerstats_collection(dockerStatsCmds,opScript):
    opScript.write("\n\n #### collectDockerStats ### \n")
    opScript.write("sleep 180\n")
    for curLine in dockerStatsCmds:
        opScript.write(str(curLine)+"\n")

def add_jaeger_scripts(allJaegerCmds,opScript):
    opScript.write("\n\n #### Collecting jaeger data ### \n")
    opScript.write("sleep 30\n")
    for curLine in allJaegerCmds:
        opScript.write(str(curLine)+"\n")


if __name__=="__main__":
    numArgs = 13
    startIter = 0
    numIters = 4
    
    if(len(sys.argv)<=numArgs):
        print ("\t Usage <baseOutputDir> <exptSetDir> <curVersionName> <startIter> <numIters> <duration> <rps> <opScriptFname> <appCode> <monitoring-machine> <frontend-machine> <email-recipient> <collect_jaeger>")
        sys.exit()
    
    baseOutputDir = sys.argv[1]
    exptSetDir = sys.argv[2]
    baseVersionName = sys.argv[3] 
    
    startIter = int(sys.argv[4])
    numIters = int(sys.argv[5])
    
    duration = int(sys.argv[6].strip())
    rps = sys.argv[7].strip()
    try:
        allRps = [int(i) for i in rps.split(',')]
    except:
        allRps = [100,200,300,400,500,550,600,650]
    
    opScriptFname = sys.argv[8].strip()
    
    appCode = sys.argv[9]
    
    monMachine = sys.argv[10]
    feMachine = sys.argv[11]
    
    generate_commands(baseOutputDir,exptSetDir,baseVersionName,startIter,numIters,duration, allRps, opScriptFname,appCode,monMachine,feMachine,emailRecipient,collect_jaeger == False) 
    
